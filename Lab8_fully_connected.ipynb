{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/irezcen/PUM_sieci_neuronowe/blob/CNN/Lab8_fully_connected.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "149710de",
      "metadata": {
        "id": "149710de"
      },
      "source": [
        "Sieci neuronowe są bardzo rozbudowanym elementem uczenia maszynowego. Często pozwalaja uzyskać bardzo dobre rezultaty w sytuacji, gdy standardowe modele klasyfikacyjne są zbyt proste i nie radzą sobie z danym zagadnieniem.\n",
        "\n",
        "Do implementacji sieci neuronowych w Pythonie stosowane są głównie dwa pakiety: TensorFlow i PyTorch. My będziemy używać tego drugiego.\n",
        "\n",
        "Zarówno TensorFlow, jak i PyTorch, zapewniają bardzo dużą swobodę w definiowaniu architektury sieci. Jest to ich duża zaleta, jednak dla początkujących osób może być to trochę problematyczne - każda klasa musi być odpowiednio zdefiniowana, trzeba samodzielnie napisać funkcje, które będą wykorzystywane do wczytywania danych i każdej epoki treningu sieci itd. Żeby ułatwić pracę użytkownikom mniej zaawansowanym i ustrukturyzować kod, stworzone zostały nakładki na oba pakiety, które upraszczają pracę z sieciami neuronowymi. W przypadku PyTorcha najczęściej używane są dwie z nich: Ignite i Lightning. My będziemy używać tego pierwszego.\n",
        "\n",
        "Do używania pakietu Ignite konieczna jest jego instalacja oraz wcześniejsza instalacja Pytorcha. Jeżeli jeszcze nie masz ich zainstalowanych, możesz zrobić to poniższym kodem. Jeżeli masz już zainstalowane oba pakiety, możesz usunąć tę komórkę i przejść od razu do importu bibliotek."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "ad299ac4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ad299ac4",
        "outputId": "97ae8996-7f25-4221-abf8-8a2d5c3a9fdf"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Looking in indexes: https://pypi.org/simple, https://us-python.pkg.dev/colab-wheels/public/simple/\n",
            "Collecting pytorch-ignite\n",
            "  Downloading pytorch_ignite-0.4.10-py3-none-any.whl (264 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.1/264.1 KB\u001b[0m \u001b[31m7.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: packaging in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite) (21.3)\n",
            "Requirement already satisfied: torch<2,>=1.3 in /usr/local/lib/python3.8/dist-packages (from pytorch-ignite) (1.13.0+cu116)\n",
            "Requirement already satisfied: typing-extensions in /usr/local/lib/python3.8/dist-packages (from torch<2,>=1.3->pytorch-ignite) (4.4.0)\n",
            "Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /usr/local/lib/python3.8/dist-packages (from packaging->pytorch-ignite) (3.0.9)\n",
            "Installing collected packages: pytorch-ignite\n",
            "Successfully installed pytorch-ignite-0.4.10\n"
          ]
        }
      ],
      "source": [
        "!pip install pytorch-ignite\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import DataLoader, TensorDataset\n",
        "from sklearn.model_selection import train_test_split\n",
        "from matplotlib import pyplot as plt\n",
        "from ignite.engine import create_supervised_trainer, create_supervised_evaluator, Events\n",
        "from ignite.metrics import Loss, Accuracy\n",
        "from ignite.contrib.handlers import ProgressBar\n",
        "from ignite.handlers import FastaiLRFinder"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3cab47e6",
      "metadata": {
        "id": "3cab47e6"
      },
      "source": [
        "Tematem, którym dotychczas nie zajmowaliśmy się na zajęciach, a stanowi bardzo istotną dziedzinę akustyki i uczenia maszynowego w akustyce jest rozpoznawanie mowy. Jest to też dobra tematyka do pokazania możliwości sieci neuronowych - już prosta sieć, wykorzystująca jedynie podstawowe rodzaje warstwo pozwala osiągnąć względnie dobre rezultaty.\n",
        "\n",
        "Dzisiaj będziemy używać najbardziej podstawowego rodzaju sieci neuronowej - sieci typu feed-forward z warstwami typu fully connected.\n",
        "\n",
        "Warstwy typu fully connected cechują się tym, że każdy neuron wejściowy warstwy połączony jest z każdym neuronem wyjściowym warstwy poprzedniej. Każde takie połączenie ma określoną wagę - te wagi to właśnie parametry sieci, które modyfikowane są podczas treningu sieci.\n",
        "\n",
        "![caption](https://4.bp.blogspot.com/-eTAX5ZojPwE/WrOuZWgFBKI/AAAAAAABCsc/YXLYgbVT4NE-hf2SoCvhHFdH3ocps9cdgCLcBGAs/s320/Capture.PNG)\n",
        "\n",
        "Sieć feed-forward cechuje się tym, że przepływ informacji pomiędzy warstwami jest jednokierunkowy i nie występują sprzężenia zwrotne - wyjście danej warstwy jest zawsze połączone tylko z wejściem kolejnej warstwy."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "792908d6",
      "metadata": {
        "id": "792908d6"
      },
      "source": [
        "Do rozpoznawania mowy stosowane są często tzw. filterbank features. Są to cechy bardzo podobne do spektrogramu i wyznaczane są jako wartości energii sygnału w poszczególnych pasmach w kolejnych ramkach sygnału. Od spektrogramu różnią się tym, że pasma wyznaczane są przez określnone banki filtrów, czyli zbiory filtrów o zadanych parametrach. Najczęściej stosownanym bankiem filtrów jest bank filtrów melowych, który poznaliśmy przy okazji omawiania MFCC. Jak już mówiliśmy przy okazji tematu ekstrakcji cech, bank ten tworzony jest przez filtry trójkątne o szerokości zależnej od częstotliwości środkowej filtra:\n",
        "![caption](https://www.researchgate.net/profile/Yusnita-Mohd-Ali/publication/288632263/figure/fig1/AS:613909065121800@1523378735077/Mel-filter-banks-basis-functions-using-20-Mel-filters-in-the-filter-bank.png)\n",
        "\n",
        "Filterbank features mogą posłużyć do późniejszego wyznaczenia MFCC - wystarczy zastosować na nich transformację kosinusową.\n",
        "\n",
        "Oba rodzaje cech znajdują zastosowanie w rozpoznawaniu mowy - poniżej przykład, jak różnią się one pomiędzy sobą."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "283c0e74",
      "metadata": {
        "id": "283c0e74"
      },
      "source": [
        "![caption](https://haythamfayek.com/assets/posts/post1/filter_banks.jpg)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "148a17c1",
      "metadata": {
        "id": "148a17c1"
      },
      "source": [
        "![caption](https://haythamfayek.com/assets/posts/post1/mfcc.jpg)\n",
        "\n",
        "Źródło obrazów: https://haythamfayek.com/2016/04/21/speech-processing-for-machine-learning.html"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1fb92f65",
      "metadata": {
        "id": "1fb92f65"
      },
      "source": [
        "Naszą pierwszą sieć służącą do rozpoznawania mowy będziemy uczyć używając cech filterbank. Przed ich ekstrakcją, przeprowadzona została filtracja filtrem preemfazy, który ma na celu uwydatnienie składowych o wyższych częstotliwościach. Dodatkowo uzyskane wartości przeliczono na skalę logarytmiczną. Wszystkie operacje zostały przeprowadzone przy użyciu biliboteki python_speech_features (http://python-speech-features.readthedocs.io/)\n",
        "\n",
        "Dane, które będziemy wykorzystywać pochodzą z bazy TensorFlow Speech Commands v0.02 (http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz) i zawierają 35 słów:\n",
        "- Yes,\n",
        "- No,\n",
        "- Up,\n",
        "- Down,\n",
        "- Left,\n",
        "- Right,\n",
        "- On,\n",
        "- Off,\n",
        "- Stop,\n",
        "- Go,\n",
        "- Zero,\n",
        "- One,\n",
        "- Two,\n",
        "- Three,\n",
        "- Four,\n",
        "- Five,\n",
        "- Six,\n",
        "- Seven,\n",
        "- Eight,\n",
        "- Nine,\n",
        "- Bed,\n",
        "- Bird,\n",
        "- Cat,\n",
        "- Dog,\n",
        "- Happy,\n",
        "- House,\n",
        "- Marvin,\n",
        "- Sheila,\n",
        "- Tree,\n",
        "- Wow.\n",
        "\n",
        "Sygnały mają długość 1s - wszystkie krótsze zostały symetrycznie uzupełnione zerami, by uzyskać stałą długość sygnału.\n",
        "\n",
        "Żeby zredukować czas potrzebny na trening sieci oraz ograniczyć rozmiar danych, będziemy analizować tylko 300 losowo wybranych nagrań każdego ze słów. W praktyce powinno wykorzystywać się możliwe duży zbiór danych - możesz samodzielnie wyliczyć cechy ze wszystkich sygnałów w bazie i wykorzystać je do treningu sieci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "cb86bbfb",
      "metadata": {
        "id": "cb86bbfb"
      },
      "outputs": [],
      "source": [
        "feats = np.load('logfbank_feats.npy')\n",
        "labels = np.load('labels.npy')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0ad1a643",
      "metadata": {
        "id": "0ad1a643"
      },
      "source": [
        "Macierz feats jest trójwymiarowa (liczba sygnałów x liczba ramek x liczba filtrów). Zwykła sieć typu feed-forward potrzebuje mieć dane opisujące pojedynczy obiekt podane w postaci wektora, a nie obrazu (macierzy 2D). Używamy więc funkcji reshape, żeby zmienić kształt danych na odpowiedni (liczba sygnałów x liczba cech, gdzie liczba cech=liczba ramek*liczba filtrów)\n",
        "\n",
        "Dane podzielimy tym razem na trzy zbiory: uczący, walidacyjny i testowy. Zbiór uczący i testowy mają takie samo zastosowanie jak zawsze - uczący wykorzystywany jest do treningu modelu, a testowy do jego ewaluacji. Zbiór walidacyjny posłuży nam do ewaluacji modelu podczas treningu.\n",
        "\n",
        "Dane podzielimy w taki sposób, by zbiór uczący zawierał 80% obiektów, a walidacyjny i testowy po 10%."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8863715b",
      "metadata": {
        "id": "8863715b"
      },
      "outputs": [],
      "source": [
        "feats = feats.reshape(feats.shape[0], -1)\n",
        "feats = feats.astype(np.float32)\n",
        "\n",
        "X_train, X_val_test, y_train, y_val_test = train_test_split(feats, labels, random_state=42, stratify=labels, train_size=0.8)\n",
        "X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, random_state=42, stratify=y_val_test, train_size=0.5)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bef517cb",
      "metadata": {
        "id": "bef517cb"
      },
      "source": [
        "Pakiety do implementacji i uczenia sieci neuronowych wymagają, by dane były w postaci tensorów, a nie \"zwykłych\" macierzy, tak jak było w przypadku dotychczas poznawanych algorytmów. Musimy więc zamienić wektory z labelami oraz macierze z cechami na tensory i utworzyć z nich TensorDataset, czyli zbiór danych w formacie dostosowanym do użycia w sieci neuronowej. Zamianę na tensory robimy przy użyciu funkcji torch.tensor."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "47b66309",
      "metadata": {
        "id": "47b66309",
        "outputId": "79ea1347-6cde-4acd-ad3d-159b4806368d"
      },
      "outputs": [
        {
          "ename": "TypeError",
          "evalue": "only size-1 arrays can be converted to Python scalars",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[1;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
            "\u001b[1;32mc:\\Users\\jakub\\OneDrive\\Pulpit\\szkola\\PUM\\Lab8_fully_connected.ipynb Cell 12\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/jakub/OneDrive/Pulpit/szkola/PUM/Lab8_fully_connected.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m trainset \u001b[39m=\u001b[39m TensorDataset(torch\u001b[39m.\u001b[39mtensor(\u001b[39mfloat\u001b[39;49m(X_train)), torch\u001b[39m.\u001b[39mtensor(\u001b[39mfloat\u001b[39m(y_train)))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jakub/OneDrive/Pulpit/szkola/PUM/Lab8_fully_connected.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m valset \u001b[39m=\u001b[39m TensorDataset(torch\u001b[39m.\u001b[39mtensor(X_val), torch\u001b[39m.\u001b[39mtensor(y_val))\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/jakub/OneDrive/Pulpit/szkola/PUM/Lab8_fully_connected.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m testset \u001b[39m=\u001b[39m TensorDataset(torch\u001b[39m.\u001b[39mtensor(X_test), torch\u001b[39m.\u001b[39mtensor(y_test))\n",
            "\u001b[1;31mTypeError\u001b[0m: only size-1 arrays can be converted to Python scalars"
          ]
        }
      ],
      "source": [
        "trainset = TensorDataset(torch.tensor(X_train), torch.tensor(y_train))\n",
        "valset = TensorDataset(torch.tensor(X_val), torch.tensor(y_val))\n",
        "testset = TensorDataset(torch.tensor(X_test), torch.tensor(y_test))"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50760f90",
      "metadata": {
        "id": "50760f90"
      },
      "source": [
        "Następnie tworzymy obiekty, które posłużą do wczytania danych przez sieć - robimy to przy pomocy funkcji DataLoader. Definiujemy w niej batch_size, czyli określamy, ile próbek ze zbioru będzie jednocześnie podane do sieci.\n",
        "Podział zbioru na części (zwane wsadami, ang. batch) pozwala nie tylko zmniejszyć zużycie pamięci (co jest szczególnie istotne przy bardzo dużych zbiorach danych), ale też zazwyczaj przyspiesza proces uczenia.\n",
        "\n",
        "Żeby w pełni zrozumieć, jak działa proces uczenia przy określonym podziale na wsady, trzeba znać pojęcie epoki.  Epoka to pojedyncze przejście wszystkich danych uczących przez całą architekturę sieci, podczas którego uaktualniane są wagi poszczególnych neuronów. Początkowo wagi dobrane są w sposób losowy (u nas) lub za pomocą aglorytmów (np. Kaiming, Xavier), a następnie zmieniane tak, by zminimalizować popełniane błędy (czyli zminimalizować loss lub zmaksymalizować dokładność).\n",
        "\n",
        "Jeżeli mamy zdefiniowany batch_size mniejszy niż cały zbiór danych, to wagi aktualizowane są podczas uczenia na każdym wsadzie, jednak epoka kończy się dopiero po przejściu przez sieć danych zawartych we wszystkich wsadach. Epoka jest wtedy dzielona na iteracje, których liczba jest równa liczbie wsadów."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c7836ed9",
      "metadata": {
        "id": "c7836ed9"
      },
      "outputs": [],
      "source": [
        "train_loader = DataLoader(trainset, batch_size=256)\n",
        "val_loader = DataLoader(valset, batch_size=256)\n",
        "test_loader = DataLoader(testset, batch_size=256)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5ac90965",
      "metadata": {
        "id": "5ac90965"
      },
      "source": [
        "Po wczytaniu i odpowiednim przygotowaniu danych możemy przejść do definicji klasy, w której będzie zapisana architektura sieci.\n",
        "\n",
        "W klasie definiujemy dwie funkcjie:\n",
        "- init: w niej określamy, jakie warstwy będą występowały w sieci (ich rodzaj i rozmiar),\n",
        "- forward: w niej określamy kolejność warstw, a tym samym kierunek przepływu danych wewnątrz sieci.\n",
        "\n",
        "Tak jak wpominaliśmy wcześniej, dzisiaj będziemy używać jedynie warstw fully connected. Będą to zwykłe warstwy liniowe, które tworzy się używając klasy nn.Linear. Do klasy jako parametry podajemy wymiary warstwy: liczbę wejść oraz liczbę wyjść.\n",
        "\n",
        "Liczba wejść warstwy musi być taka sama, jak liczba wyjść poprzedniej warstwy. W przypadku pierwszej warstwy w sieci liczba wejść musi być tak dobrana, by pasowała do rozmiaru danych uczących. W naszych danych każdy sygnał opisany jest przy pomocy 2574 cech, więc taka musi być liczba wejść pierwszej warstwy.\n",
        "\n",
        "Liczba wyjść ostatniej warstwy powinna być równa liczbie klas, które znajdują się w danych. My mamy 35 klas, więc tyle też wyjść ustalamy w warstwie 3.\n",
        "\n",
        "W funkcji forward określa się też, jaka funkcja aktywacji będzie użyta w ostatniej warstwie. Dobór funkcji aktywacji ma wpływ na uzyskiwane wyniki klasyfikacji, ponieważ to ona służy do obliczenia wartości pojawiającej się na wyjściu całej sieci. Jest wiele różnych funkcji aktywacji o różnych zastosowaniach - my będziemy używać funkcji log_softmax, czyli logarytmowanej znormalizowanej funkcji wykładniczej (zwanej też funkcją logistyczną). Softmax pozwala uzyskać na wyjściu sieci wektor prawdopodobieństw przynależności obiektu do każdej z klas, natomiast zastosowanie logarytmu jest szybsze pod względem numerycznym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "615e4755",
      "metadata": {
        "id": "615e4755"
      },
      "outputs": [],
      "source": [
        "class Net(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Net, self).__init__()\n",
        "        self.fc1 = nn.Linear(2574, 256)\n",
        "        self.fc2 = nn.Linear(256, 120)\n",
        "        self.fc3 = nn.Linear(120, 35)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "92f69da8",
      "metadata": {
        "id": "92f69da8"
      },
      "source": [
        "Musimy też określić, na czym będą wykonywane obliczenia, czyli czy mamy dostępną kartę graficzną, czy też będziemy korzystać ze zwykłego procesora. Robi się to używając zmiennej device - funkcją torch.cuda.is_available() sprawdzamy, czy jest dostępna karta graficzna. Jeżeli tak, to chcemy jej użyć (device=\"cuda\"), jeżeli nie, to musimy zadowolić się procesorem (device=\"cpu\").\n",
        "\n",
        "Powoli zbliżamy się do zakończenia konfiguracji wszystkich ustawień sieci i treningu. Zostało nam do określenia jeszcze kilka istotnych parametrów. Przede wszystkim, musimy ustalić, jakie będzie kryterium uczenia się sieci i do czego będzie ona dążyć, czyli zmienną criterion. Użyjemy nn.NLLLoss (ang. negative log likelihood loss) - im mniejszą wartość będzie przyjmować, tym mniejsza różnica pomiędzy klasą rzeczywistą a predykcją sieci. NLLLoss jest odpowiednikiem entropii krzyżowej w sytuacji, gdy prawdopodobieństwa są zlogarytmowane (z użyciem log_softmax).\n",
        "\n",
        "Mamy dużo klas, więc przeanalizujmy, jak jest to obliczane w prostszym przypadku softmax - entropia krzyżowa.\n",
        "\n",
        "Przy okazji omawiania metryki log loss (straty logarytmicznej, inaczej nazywanej właśnie entropią krzyżową) wyliczaliśmy tzw. prawdopodobieństwa skorygowane. Wynikało to z tego, że binarne modele regresyjne mają tylko jedno wyjście i prawdopodobieństwo mniejsze od zdefiniowanego progu oznaczało przynależność do klasy 0, a większe - do klasy 1.\n",
        "\n",
        "W przypadku sieci neuronowej i klasyfikacji wieloklasowej mamy tyle wyjść, ile klas, nie trzeba więc liczyć prawdopodobieństw skorygowanych - każde wyjście zwraca prawdopodobieństwo przynależności obiektu do jednej, konkretnej klasy. W takim przypadku entropia krzyżowa jest liczona jako ujemna średnia logarytmiczna prawdopodobieństw zwróconych przez odpowiednie wyjścia (te, które odpowiadają rzeczywistym klasom rozważanych obiektów)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "66eaa846",
      "metadata": {
        "id": "66eaa846"
      },
      "source": [
        "Kolejnym istotnym krokiem jest dobór optimizera. Optimizer służy do optymalizacji wag modelu czyli zmieniania ich w taki sposób, żeby osiągnąć zadane kryterium, np. minimalną wartość NLLLoss.\n",
        "\n",
        "Jednym z najczęściej używanych optimizerów jest optimizer SGD, który wykorzystuje stochastyczny spadek gradientu (ang. stochastic gradient descent). Metoda ta polega na wyliczaniu gradientu funkcji kosztu - gradient jest uogólnieniem pochodnej w sytuacji, gdy dotyczy ona wektora i zawiera wszystkie pochodne cząstkowe tego wektora. Gdy zbliżamy się do minimum funkcji, gradient zanika.\n",
        "\n",
        "Prościej będzie wytłumaczyć zasadę działania bardziej podstawowej wersji algorytmu, czyli metody gradientu prostego, która składa się z 5 kroków:\n",
        "1. wyznaczenie gradientu funkcji kosztu,\n",
        "2. wybranie losowych wartości parametrów (w tym przypadku wag neuronów),\n",
        "3. wyliczenie gradientu na podstawie wartości parametrów,\n",
        "4. wyliczenie wielkości kroku, o który zmienimy wartości parametrów zgodnie ze wzorem: step size = gradient * learning rate\n",
        "5. wyliczenie nowych wartości parametrów: new params = old params - step size,\n",
        "6. powtarzenie kroków 3-5 do momentu uzyskania gradientu równego 0.\n",
        "\n",
        "Jak już zostało wspomniane powyżej, wielkość kroków podczas zmiany parametrów określana jest przez współczynnik uczenia (ang. learning rate). Im większy współczynnik, tym większe większe kroki są stosowane - to zapewnia szybszy proces optymalizacji wag (a w konsekwencji uczenia sieci), ale też powoduje ryzyko \"przeskoczenia\" nad wartościa optymalną i może pogorszyć ostateczne rezultaty.\n",
        "![caption](https://miro.medium.com/max/724/1*AqatzLelQw8LO9XuPCdfFw.png)\n",
        "\n",
        "Z kolei zbyt mała wartość współczynnika znacząco wydłuża proces optymalizacji, co również nie jest korzystne.\n",
        "\n",
        "Metoda SGD różni się od metody gradientu prostego tym, że nie korzysta się w niej z gradientu wyliczonego na całym zbiorze danych uczących, ponieważ jest to czaso- i kosztochłonne. Zamiast tego estymuje się wartość gradientu na podstawie losowo wybranego jednego elementu ze zbioru danych - stąd nazwa stochastyczny gradient."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "37f096d8",
      "metadata": {
        "id": "37f096d8"
      },
      "outputs": [],
      "source": [
        "device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
        "# print(device)\n",
        "criterion = nn.NLLLoss()\n",
        "model = Net()\n",
        "model.to(device)  # Move model before creating optimizer\n",
        "optimizer = optim.SGD(model.parameters(), lr=1e-8, momentum=0.9)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "eea065b6",
      "metadata": {
        "id": "eea065b6"
      },
      "source": [
        "W kolejnym kroku inicjalizujemy zmienne, w których będą zapisywane aktualne stany modelu i optimizera."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b05b6883",
      "metadata": {
        "id": "b05b6883"
      },
      "outputs": [],
      "source": [
        "init_model_state = model.state_dict()\n",
        "init_opt_state = optimizer.state_dict()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e74767f",
      "metadata": {
        "id": "3e74767f"
      },
      "source": [
        "Następnie musimy zdefiniować dwa obiekty - trainer i evaluator.\n",
        "\n",
        "Trainer służy do uczenia sieci - podaje się do niego model (sieć), criterion i device. Podczas użycia trainera aktualizowane są wagi modelu w taki sposób, by dążyć do ekstremum zdefiniowanego kryterium (w tym przypadku do minimum, bo naszym kryterium jest NLLLoss).\n",
        "\n",
        "Evaluator służy do ewaluacji sieci, czyli do walidacji oraz do wyliczenia metryk na zbiorze testowym - podczas jego użycia nie są aktualizowane wagi. Do niego podajemy model oraz metryki, które mają być użyte.\n",
        "\n",
        "Dodatkowo, żeby mieć kontrolę nad przebiegiem treningu i tym, jaka część została już wykonana, użyjemy paska postępu wyświetlanego funkcją ProgressBar. Będzie on wyświetlał wyniki uzyskane na zbiorze uczącym podczas kolejnych epok."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "238f8c18",
      "metadata": {
        "id": "238f8c18"
      },
      "outputs": [],
      "source": [
        "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
        "evaluator = create_supervised_evaluator(model, metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.NLLLoss())}, device=device)\n",
        "ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"batch loss\": x})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a7f8b52",
      "metadata": {
        "id": "1a7f8b52"
      },
      "source": [
        "Przed rozpoczęciem treningu sieci należy zdefiniować liczbę epok. Po każdej epoce można wyliczyć metryki uzyskiwane na zbiorze walidacyjnym - jest to zbiór danych, które nie są podawane do sieci w celu uczenia, więc uzyskane na nich metryki pozwalają ocenić, czy sieć się uczy oraz czy się nie przeucza.\n",
        "\n",
        "Żeby przeprowadzić walidację w pakiecie ignite trzeba wywołać evaluator, do którego podaje się dane walidacyjne. Ten evaluator musi być umieszczony w funkcji \"podpiętej\" pod trainer - poniżej przykład, jak to zrobić i spowodować, że po każdej epoce będą wyświetlane wyniki walidacji.\n",
        "\n",
        "Po zakończonym treningu evaluator posłuży nam do wyliczenia metryk na zbiorze testowym."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "81ab15e9",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "adeab135dd2147fbacb4489521d7f272",
            "0f4bfd3d34ef483d81b4c2c053c036f0",
            "bfff01022d584254b834d049d33f20e3",
            "37207af0ed7a437aa2a9e09e6acb54c9",
            "14ca3c0ec3c24eec834efb9746b3f8b6",
            "d80f4ab8f0ec44f5999af3e9b6625824",
            "0eac8dbabe6c4f3ca317765414570e2d",
            "cba987b0c6b24844bfbdfcf4526abf32",
            "7be07add37324bfe9803448e7cb7a1b6",
            "1968deb4989b432d86e310f2c3e83588"
          ]
        },
        "id": "81ab15e9",
        "outputId": "c1b6da60-0f63-4e65-ff1b-40f251f0d752"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "adeab135dd2147fbacb4489521d7f272",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1  Avg accuracy: 0.02 Avg loss: 5.78\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0f4bfd3d34ef483d81b4c2c053c036f0",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 2  Avg accuracy: 0.02 Avg loss: 5.76\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "bfff01022d584254b834d049d33f20e3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 3  Avg accuracy: 0.02 Avg loss: 5.74\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "37207af0ed7a437aa2a9e09e6acb54c9",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 4  Avg accuracy: 0.02 Avg loss: 5.71\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "14ca3c0ec3c24eec834efb9746b3f8b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 5  Avg accuracy: 0.02 Avg loss: 5.69\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "d80f4ab8f0ec44f5999af3e9b6625824",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 6  Avg accuracy: 0.02 Avg loss: 5.67\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "0eac8dbabe6c4f3ca317765414570e2d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 7  Avg accuracy: 0.02 Avg loss: 5.65\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cba987b0c6b24844bfbdfcf4526abf32",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 8  Avg accuracy: 0.02 Avg loss: 5.62\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "7be07add37324bfe9803448e7cb7a1b6",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 9  Avg accuracy: 0.02 Avg loss: 5.60\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "1968deb4989b432d86e310f2c3e83588",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 10  Avg accuracy: 0.02 Avg loss: 5.58\n",
            "{'acc': 0.022857142857142857, 'loss': 5.516507626488095}\n"
          ]
        }
      ],
      "source": [
        "@trainer.on(Events.EPOCH_COMPLETED) #określamy, że walidacja ma być przeprowadzona po zakończeniu epoki\n",
        "def log_validation_results(trainer):\n",
        "    evaluator.run(val_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\" #określamy, że dokładność i loss \n",
        "                                                                                #mają być wyświetlone z dokładością \n",
        "                                                                                #do 2 miejsc po przecinku\n",
        "          .format(trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
        "\n",
        "#trainer.run(trainloader, max_epochs=1000)\n",
        "trainer.run(train_loader, max_epochs=150)\n",
        "\n",
        "evaluator.run(test_loader)\n",
        "print(evaluator.state.metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "658ab81a",
      "metadata": {
        "id": "658ab81a"
      },
      "source": [
        "Współczynnik uczenia może być dobierany w sposób automatyczny, służy do tego funkcja FastaiLRFinder. Dobrana wartość zależy od tego, ile wynosi parametr diverge_th - poszukiwania najlepszej wartośći współczynnika uczenia przerywane są w momencie, gdy zostanie spełnione kryterium current loss > diverge_th * best_loss.\n",
        "\n",
        "diverge_th może być dowolną liczbą nie mniejszą niż 1, domyślnie wynosi 5. Mniejsza wartość powoduje szybsze zakończenie poszukiwań najlepszego współczynnika uczenia, jednak jest dość ryzykowne - jeżeli na początku poszukiwac trafimy na minimum lokalne, to szukanie zostanie zakończone. W praktyce może okazać się, że niezatrzymanie poszukiwań i zezwolenie na tymczasowe osiąganie większych wartości current_loss pozwoliłoby trafić na minimum globalne lub przynajmniej \"lepsze\" minimum lokalne, a tym samym lepiej dobrać wartość parametru i w konsekwencji przeprowadzić bardziej efektywny trening sieci."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f8008b55",
      "metadata": {
        "scrolled": true,
        "colab": {
          "referenced_widgets": [
            "445f17db292c4dadbfd59691daa3782d"
          ]
        },
        "id": "f8008b55",
        "outputId": "d1281ac1-3e97-491a-c371-0886efaf7b00"
      },
      "outputs": [
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "445f17db292c4dadbfd59691daa3782d",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1  Avg accuracy: 0.03 Avg loss: 5.15\n",
            "Suggested LR 2.154434690031884e-08\n"
          ]
        }
      ],
      "source": [
        "lr_finder = FastaiLRFinder()\n",
        "to_save={'model': model, 'optimizer': optimizer}\n",
        "with lr_finder.attach(trainer, to_save, diverge_th=1.05, start_lr=1e-8, end_lr=1e-7) as trainer_with_lr_finder:\n",
        "    #domyślnie start_lr jest taki, jak określony w optimizerze, a end_lr=10\n",
        "    trainer_with_lr_finder.run(train_loader)\n",
        "\n",
        "print(\"Suggested LR\", lr_finder.lr_suggestion())"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c0250df9",
      "metadata": {
        "id": "c0250df9"
      },
      "source": [
        "Po znalezieniu najlepszej wartości współczynnika uczenia trzeba ustawić tę wartość w optimizerze - robi się to funkcją apply_suggested_lr. Następnie trzeba ponownie przeprowadzić trening sieci.\n",
        "\n",
        "Ponownie inicjalizujemy trainer - jeżeli tego nie zrobimy, to zamiast uczyć nową sieć neuronową będziemy kontynuować trening poprzedniej, co nie pozwoli nam dobrze przeanalizować wpływu parametru learning rate na proces uczenia."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "545ddd44",
      "metadata": {
        "colab": {
          "referenced_widgets": [
            "e31a19867e9746a4b524ee4ae544b051",
            "8079c022897148e899c180b55887de8b",
            "3a6c718a8c8b4cee8a58e726a92ffd47",
            "f20e458faa384c8b81115c9a024e89de",
            "a3dbe386e4b94aadbfa329508f7c2ff3",
            "2386f4b21294477d85ea895ae2b22bc2",
            "e3160751321143fdbaa4d259e6610f98",
            "dad866803e2d4c00a2e4af0fa8ccec26",
            "4118e222d96b423bbe6c965b59d2f772",
            "cbbf8435f46b4a1386afb56822ca0673"
          ]
        },
        "id": "545ddd44",
        "outputId": "2ebb58f4-e178-4735-d6ed-80d829147fca"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training with suggested lr:  2.154434690031884e-08\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e31a19867e9746a4b524ee4ae544b051",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 1  Avg accuracy: 0.02 Avg loss: 5.54\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "8079c022897148e899c180b55887de8b",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 2  Avg accuracy: 0.02 Avg loss: 5.50\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "3a6c718a8c8b4cee8a58e726a92ffd47",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 3  Avg accuracy: 0.02 Avg loss: 5.45\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "f20e458faa384c8b81115c9a024e89de",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 4  Avg accuracy: 0.02 Avg loss: 5.42\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "a3dbe386e4b94aadbfa329508f7c2ff3",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 5  Avg accuracy: 0.02 Avg loss: 5.38\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "2386f4b21294477d85ea895ae2b22bc2",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 6  Avg accuracy: 0.02 Avg loss: 5.34\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "e3160751321143fdbaa4d259e6610f98",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 7  Avg accuracy: 0.02 Avg loss: 5.30\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "dad866803e2d4c00a2e4af0fa8ccec26",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 8  Avg accuracy: 0.02 Avg loss: 5.27\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "4118e222d96b423bbe6c965b59d2f772",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 9  Avg accuracy: 0.02 Avg loss: 5.24\n"
          ]
        },
        {
          "data": {
            "application/vnd.jupyter.widget-view+json": {
              "model_id": "cbbf8435f46b4a1386afb56822ca0673",
              "version_major": 2,
              "version_minor": 0
            },
            "text/plain": [
              "[1/33]   3%|3          [00:00<?]"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation Results - Epoch: 10  Avg accuracy: 0.02 Avg loss: 5.21\n",
            "{'acc': 0.021904761904761906, 'loss': 5.150043247767857}\n"
          ]
        }
      ],
      "source": [
        "trainer = create_supervised_trainer(model, optimizer, criterion, device=device)\n",
        "# evaluator = create_supervised_evaluator(model, metrics={\"acc\": Accuracy(), \"loss\": Loss(nn.NLLLoss())}, device=device)\n",
        "ProgressBar(persist=True).attach(trainer, output_transform=lambda x: {\"batch loss\": x})\n",
        "\n",
        "@trainer.on(Events.EPOCH_COMPLETED)\n",
        "def log_validation_results(trainer):\n",
        "    evaluator.run(val_loader)\n",
        "    metrics = evaluator.state.metrics\n",
        "    print(\"Validation Results - Epoch: {}  Avg accuracy: {:.2f} Avg loss: {:.2f}\"\n",
        "          .format(trainer.state.epoch, metrics['acc'], metrics['loss']))\n",
        "\n",
        "lr_finder.apply_suggested_lr(optimizer)\n",
        "print('Training with suggested lr: ', optimizer.param_groups[0]['lr'])\n",
        "#trainer.run(trainloader, max_epochs=1000)\n",
        "trainer.run(train_loader, max_epochs=150)\n",
        "\n",
        "evaluator.run(test_loader)\n",
        "print(evaluator.state.metrics)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "cbc9978e",
      "metadata": {
        "id": "cbc9978e"
      },
      "source": [
        "Sieci neuronowe, zwłaszcza głębokie, mają niestety tendencję do przeuczania się  przy małej liczbie danych uczących. Nie zawsze jesteśmy w stanie powiększyć zbiór uczący o nowe dane, więc konieczne jest zastosowanie innych technik pozwalających zmniejszyć przeuczenie.\n",
        "\n",
        "Jedną z takich technik jest dropout. Polega on na losowym \"wyłączaniu\" neuronów podczas kolejnych iteracji (czyli ustawianiu ich wag na 0) oraz skalowaniu niewyłączonych przez współczynnik 1/(1-p), gdzie p to zadany parametr dropoutu. Dzięki temu sieć nie może dopasować się idealnie do danych uczących, ponieważ podczas treningu musi dopasować wagi w taki sposób, by uzyskać dobre rezultaty również wtedy, gdy część neuronów będzie nieaktywna.\n",
        "\n",
        "Definiując warstwę dropout należy określić, z jakim prawdopodobieństwem neurony będą \"wyłączane\". Domyślnie to prawdopodobieństwo wynosi 0.5 - można tę wartość zmienić, ale należy robić to w sposób przemyślany. Jeżeli ustawimy zbyt dużą wartość prawdopodobieństwa, to sieć może nie być w stanie w ogóle nauczyć się klasyfikować danych. Jeżeli ustawimy wartość zbyt małą, to regularyzacja może być nieefektywna i nie zmniejszymy przeuczenia sieci.\n",
        "\n",
        "Jeżeli planujesz użyć dropoutów, zwłaszcza z różnymi wartościami p, to dobrze jest je zdefiniować w funkcji \\_\\_init\\_\\_ i potem odnosić się do nich po nazwie w funkcji forward, np.\n",
        "\n",
        "def \\_\\_init\\_\\_(self):\n",
        "\n",
        "    self.fc1 = nn.Linear(2574, 256)\n",
        "    self.fc2 = nn.Linear(256, 120)\n",
        "    self.fc3 = nn.Linear(120, 35)\n",
        "    self.dropout1 = nn.Dropout(p=0.5)\n",
        "    self.dropout2 = nn.Dropout(p=0.2)\n",
        "    \n",
        "def forward(self, x):\n",
        "\n",
        "        x = self.fc1(x)\n",
        "        x = self.dropout1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.dropout2(x)\n",
        "        x = self.fc3(x)\n",
        "        return F.log_softmax(x, dim=1)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6331812f",
      "metadata": {
        "id": "6331812f"
      },
      "source": [
        "Spróbuj zmienić architekturę sieci tak, by uzyskać lepsze wyniki na zbiorze walidacyjnym i zbiorze testowym.\n",
        "\n",
        "Możesz to zrobić:\n",
        "- zwiększając liczbę warstw (uwaga na liczbę wejść i wyjść),\n",
        "- dodając dropout,\n",
        "- zmieniając funkcję aktywacji warstw (wszystkich lub niektórych), np.: x = F.relu(self.fc1(x))\n",
        "- zmieniając optimizer.\n",
        "\n",
        "Po zmianach zwróć uwagę, czy ustalona liczba epok wystarcza do nauczenia sieci - jeżeli do ostatniej epoki obserwujesz wzrost dokładności na zbiorze walidacyjnym, to prawdopodobnie sieć nadal nie jest w pełni nauczona i powinno się zwiększyć liczbę epok. Jeżeli od pewnego momentu treningu obserwujesz spadek dokładności, to sieć zaczęła się przeuczać i trzeba zmniejszyć liczbę epok (uwaga: musi to być trend spadkowy, a nie tylko pojedyncze spadki - one nic nie znaczą)."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "00df457a",
      "metadata": {
        "id": "00df457a"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.2"
    },
    "vscode": {
      "interpreter": {
        "hash": "f0cf854484826becf69b9363a35f769a3f32573db803431254cc95fc20fb81b2"
      }
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}